<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/mhealth-course/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/mhealth-course/assets/css/just-the-docs-head-nav.css"> <style id="jtd-nav-activation"> .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.external) > .nav-list-link, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.external) > .nav-list > .nav-list-item > .nav-list-link, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.external) > .nav-list > .nav-list-item > .nav-list > .nav-list-item:not(:nth-child(1)) > .nav-list-link { background-image: none; } .site-nav > .nav-list:not(:nth-child(1):not(.nav-category-list)) .nav-list-link, .site-nav .nav-list-link.external { background-image: none; } .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.external):nth-child(1) > .nav-list > .nav-list-item:nth-child(3) > .nav-list > .nav-list-item:nth-child(1) > .nav-list-link { font-weight: 600; text-decoration: none; } .site-nav > .nav-category-list > .nav-list-item > .nav-list-expander svg, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(1) > .nav-list-expander svg, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(1) > .nav-list > .nav-list-item:nth-child(3) > .nav-list-expander svg { transform: rotate(-90deg); } .site-nav > .nav-category-list > .nav-list-item > .nav-list, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(1) > .nav-list, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(1) > .nav-list > .nav-list-item:nth-child(3) > .nav-list { display: block; } </style> <script src="/mhealth-course/assets/js/vendor/lunr.min.js"></script> <script src="/mhealth-course/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="/mhealth-course/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Detection vs Classification | mHealth Analytics</title> <meta name="generator" content="Jekyll v3.9.3" /> <meta property="og:title" content="Detection vs Classification" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Activity Recognition" /> <meta property="og:description" content="Activity Recognition" /> <link rel="canonical" href="http://localhost:4000/mhealth-course/chapter3-activityrecognition/ch3-detection-vs-classification.html" /> <meta property="og:url" content="http://localhost:4000/mhealth-course/chapter3-activityrecognition/ch3-detection-vs-classification.html" /> <meta property="og:site_name" content="mHealth Analytics" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Detection vs Classification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Activity Recognition","headline":"Detection vs Classification","url":"http://localhost:4000/mhealth-course/chapter3-activityrecognition/ch3-detection-vs-classification.html"}</script> <!-- End Jekyll SEO tag --> #<link href="https://fonts.googleapis.com/css?family=Lucinda" rel="stylesheet"> <link rel="shortcut icon" type="image/x-icon" href="/mhealth-course/assets/images/favicon.ico"> <!-- Mar 19, 2020: Just switched from cdn.mathjax.org to cdnjs based on https://www.mathjax.org/cdn-shutting-down/--> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "none" } }, tex2jax: { inlineMath: [['$','$'], ['\\(','\\)'], ['\[','\]']], displayMath: [['$$', '$$']], processEscapes: true, processEnvironments: true } }); MathJax.Hub.Register.StartupHook('TeX Jax Ready', function () { MathJax.InputJax.TeX.prefilterHooks.Add(function (data) { data.math = data.math.replace(/^% <!\[CDATA\[/, '').replace(/%\]\]>$/, ''); }); }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML"></script> #<link rel="stylesheet" href="/mhealth-course/assets/css/custom.css"> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.css"> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/mhealth-course/" class="site-title lh-tight"> mHealth Analytics </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Mobile Sensing &amp; Analytics category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mhealth-course/" class="nav-list-link">Mobile Sensing &amp; Analytics</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Data Smoothing category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mhealth-course/chapter1-noise/chapter1.html" class="nav-list-link">Data Smoothing</a><ul class="nav-list"><li class="nav-list-item"> <a href="/mhealth-course/chapter1-noise/ch1-intro.html" class="nav-list-link">Intro to Data Smoothing</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter1-noise/ch1-timedomainfiltering.html" class="nav-list-link">Time-domain Smoothing</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter1-noise/ch1-sampling-nyquist.html" class="nav-list-link">Sampling and Nyquist</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter1-noise/ch1-freqdomainfiltering.html" class="nav-list-link">Freq-domain Filtering</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Step Counting category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mhealth-course/chapter2-steps/chapter2.html" class="nav-list-link">Step Counting</a><ul class="nav-list"><li class="nav-list-item"> <a href="/mhealth-course/chapter2-steps/ch2-intro.html" class="nav-list-link">Intro to Step Counting</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter2-steps/ch2-stepcounter.html" class="nav-list-link">Step Detection Algorithm</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter2-steps/ch2-calories.html" class="nav-list-link">Counting Calories</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Activity Recognition category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mhealth-course/chapter3-activityrecognition/chapter3.html" class="nav-list-link">Activity Recognition</a><ul class="nav-list"><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-detection-vs-classification.html" class="nav-list-link">Detection vs Classification</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-visualizing-activities.html" class="nav-list-link">Visualizing activities</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-time-domain-features.html" class="nav-list-link">Time domain features</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-freq-domain-features.html" class="nav-list-link">Freq domain features</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-decision-tree.html" class="nav-list-link">Decision Tree Classifier</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-decision-tree-example.html" class="nav-list-link">Cardiac Risk Prediction</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-overfitting.html" class="nav-list-link">Overcoming Overfitting</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter3-activityrecognition/ch3-classifier-performance.html" class="nav-list-link">Evaluating Classifier Performance</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Heart Rhythm Sensing category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mhealth-course/chapter4-heartrhythm/chapter4.html" class="nav-list-link">Heart Rhythm Sensing</a><ul class="nav-list"><li class="nav-list-item"> <a href="/mhealth-course/chapter4-heartrhythm/ch4-ppg.html" class="nav-list-link">Photoplethysmography (PPG)</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter4-heartrhythm/ch4-ecg-ppg-analysis.html" class="nav-list-link">PPG Analysis</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Vocal Biomarkers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mhealth-course/chapter5-voiceanalytics/chapter5.html" class="nav-list-link">Vocal Biomarkers</a><ul class="nav-list"><li class="nav-list-item"> <a href="/mhealth-course/chapter5-voiceanalytics/ch5-audiofeatures.html" class="nav-list-link">Audio Features</a> </li><li class="nav-list-item"> <a href="/mhealth-course/chapter5-voiceanalytics/ch5-audioclassification.html" class="nav-list-link">Audio Classification</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Measuring Sleep Patterns category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mhealth-course/chapter6-sleepsensing/chapter6.html" class="nav-list-link">Measuring Sleep Patterns</a><ul class="nav-list"></ul></li></ul></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search mHealth Analytics" aria-label="Search mHealth Analytics" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/mhealth-course/">Mobile Sensing &amp; Analytics</a></li> <li class="breadcrumb-nav-list-item"><a href="/mhealth-course/chapter3-activityrecognition/chapter3.html">Activity Recognition</a></li> <li class="breadcrumb-nav-list-item"><span>Detection vs Classification</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h2 class="no_toc" id="human-activity-recognition"> <a href="#human-activity-recognition" class="anchor-heading" aria-labelledby="human-activity-recognition"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Human Activity Recognition </h2> <h2 class="no_toc text-delta" id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of Contents </h2> <ol id="markdown-toc"> <li><a href="#chapter-3-activity-recognition-using-inertial-sensors-slides" id="markdown-toc-chapter-3-activity-recognition-using-inertial-sensors-slides">Chapter 3: Activity Recognition using Inertial Sensors [Slides]</a> <ol> <li><a href="#detection-counting-steps" id="markdown-toc-detection-counting-steps">Detection: Counting Steps</a></li> <li><a href="#classification-recognizing-activities" id="markdown-toc-classification-recognizing-activities">Classification: Recognizing Activities</a></li> <li><a href="#from-raw-data-to-activity-labels" id="markdown-toc-from-raw-data-to-activity-labels">From Raw Data to Activity Labels</a></li> <li><a href="#summing-up" id="markdown-toc-summing-up">Summing Up</a></li> </ol> </li> <li><a href="#implementing-feature-extraction-in-python" id="markdown-toc-implementing-feature-extraction-in-python">Implementing feature extraction in Python</a> <ol> <li><a href="#the-resample-function" id="markdown-toc-the-resample-function">The <code class="language-plaintext highlighter-rouge">resample</code> function</a></li> </ol> </li> <li><a href="#notebook-step-counting-with-find-peaks-html-ipynb" id="markdown-toc-notebook-step-counting-with-find-peaks-html-ipynb">Notebook: Step Counting with Find Peaks [html] [ipynb]</a></li> </ol><hr /> <h2 id="chapter-3-activity-recognition-using-inertial-sensors-slides"> <a href="#chapter-3-activity-recognition-using-inertial-sensors-slides" class="anchor-heading" aria-labelledby="chapter-3-activity-recognition-using-inertial-sensors-slides"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Chapter 3: Activity Recognition using Inertial Sensors [<a href="https://drive.google.com/file/d/1qfVTzDZgv0Lk49Z2MUrz-yQPi1wBF5xX/view?usp=drive_link">Slides</a>] </h2> <p>Let’s turn to a concrete example to illustrate how activity recognition can work. Consider the case where we want to identify whether a person is sitting, standing, jogging, walking upstairs, walking downstairs or driving a car. Our hypothesis is that each of these activities involves a different “signature” that can help detect the current state of the user. But this process is very different from the methods that you used so far to detect steps.</p> <h3 id="detection-counting-steps"> <a href="#detection-counting-steps" class="anchor-heading" aria-labelledby="detection-counting-steps"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Detection: Counting Steps </h3> <p>Recall your first assignment: detecting steps. At the heart of the step counter algorithm is the detection paradigm. Here, the primary objective is to identify and quantify singular, temporally-constrained events from a continuous stream of data. In our step counting exercise, each step was represented as a peak in the accelerometer data. Using Python’s <code class="language-plaintext highlighter-rouge">find_peaks</code>, you designed algorithms to pick out these individual events, identifying the rhythmic up-down motion of walking.</p> <p>In this detection-based approach, the emphasis is on the temporal accuracy of detecting singular, repetitive events. However, this approach focuses on micro-scale details and might not be optimal for understanding broader behaviors or activities.</p> <h3 id="classification-recognizing-activities"> <a href="#classification-recognizing-activities" class="anchor-heading" aria-labelledby="classification-recognizing-activities"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Classification: Recognizing Activities </h3> <p>Now, think of activities as broader categories: walking, jogging, sitting, standing, etc. Unlike steps, these are not singular events but span over durations, often encompassing various movements and patterns. Recognizing such activities isn’t about finding a single peak but capturing the holistic ‘signature’ of a movement over time.</p> <p>For activity recognition, instead of analyzing each data point in isolation, we use a “rolling window” approach. This means we capture chunks (windows) of continuous data, extracting meaningful features from them, and then associating them with a specific activity label. This window can either overlap with the previous one, ensuring continuity, or be distinct, depending on our application requirements. By comparing it with the simple step detection, you can see that activity recognition deals with longer timescales.</p> <p>But why the rolling window? Let’s think of a classroom analogy. Instead of assessing a student based on one answer, imagine if we evaluate their performance over a series of questions. This gives a more comprehensive view of their capabilities. Similarly, by analyzing chunks of data rather than individual data points, we can understand broader patterns and behaviors. This is shown in the figure below - the table of 3-axis accelerometer data is aggregated into windows of data (100 samples in the figure). Two cases are illustrated - in the above case, each rolling window shifts by half the window size and in the below case, there is no overlap. Both are used in practice.</p> <p>Whether overlapping or distinct, each window represents a ‘snapshot’ of movement, which is then transformed into a set of features (we will discuss what these features are in just a bit but for now lets focus on the concept). This is a crucial distinction from the step counting, where we were only interested in specific, singular peaks.</p> <p>Two points to note regarding use of rolling windows:</p> <ul> <li>At a procedural level, the rolling window in classification is similar to rolling windows that we used for smoothing but with the crucial difference that we shifted by one sample in the smoothing case, whereas we shift by a full window or half window in this case. This is because the goal is different - in smoothing, we want to keep the same data length but just smooth the data whereas here, we want to aggregate data into say chunks over a longer window to determine what activity is occurring.</li> <li>The window size should be selected such that it is long enough to recognize the activity of interest. For example, if the goal is to recognize walking up the stairs, then an appropriate window may be a few seconds. Neither very short windows (e.g. one second) nor very long windows (e.g. 10 minutes) would be appropriate since there would be either too little information (former case) or the activity of interest may be mixed with other activities making it difficult to recognize (latter case).</li> </ul> <h3 id="from-raw-data-to-activity-labels"> <a href="#from-raw-data-to-activity-labels" class="anchor-heading" aria-labelledby="from-raw-data-to-activity-labels"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> From Raw Data to Activity Labels </h3> <p float="left"> <img src="images/raw-data-to-features.png" alt="drawing" width="500" /> </p> <p>With the conceptual groundwork laid, let’s understand the process of building an efficient activity recognition system. Here’s a comprehensive breakdown of each stage:</p> <ol> <li><strong>Data Collection:</strong> The first and probably most important step of any activity recognition system is collecting high quality labeled data across many individuals, many different real-world conditions with different noise characteristics. Before diving into classification, it’s imperative to gather labeled datasets for each targeted activity. This typically involves participants or volunteers engaging in predefined activities while a recording device, often a smartphone or wearable, logs the sensor data. When generating labeled data:</li> </ol> <ul> <li>Ensure a balanced dataset across all activity categories.</li> <li>Encourage participants to carry devices in various orientations to ensure orientation-agnostic algorithms.</li> <li>Gather sufficient longitudinal data per activity so you can break it down into windows.</li> </ul> <ol> <li> <p><strong>Feature Extraction:</strong> The raw sensor data, while information-rich, isn’t immediately fit for classification. One needs to extract the features, the identifiable patterns, and characteristics before using the data for classification models. Here, rolling windows segment the data, with each segment undergoing feature extraction.</p> <ul> <li><strong>Time-domain Features:</strong> Simple statistical measures such as mean, median, variance, and standard deviation can capture essential characteristics of the data.</li> <li><strong>Frequency-domain Features:</strong> Techniques like Fourier Transforms convert time-domain signals into their frequency components, enabling recognition of repetitive patterns, which are crucial in activities like walking or running.</li> <li><strong>Similarity-based Features:</strong> Methods like Dynamic Time Warping (DTW) can help in understanding the similarity between two temporal sequences, useful in matching activity patterns.</li> <li><strong>Others:</strong> Depending on the application, features capturing peak values, zero-crossings, or wavelet-based characteristics might also be of interest.</li> </ul> </li> <li><strong>Model Training:</strong> Having extracted a plethora of features, the next step is model training, where algorithms learn the mapping between these features and the corresponding activity labels. There are many machine learning algorithms but we will look at a few simpler ones in this class. <ul> <li><strong>Decision Trees (DT):</strong> Simple yet effective, DTs can classify data based on certain decision rules.</li> <li><strong>Random Forests (RF):</strong> An ensemble of DTs, RFs offer improved accuracy and robustness.</li> </ul> </li> <li><strong>Prediction:</strong> The trained model can now be downloaded to a smartphone or smartwatch for performing real-time predictions. For example, think of your smartphone or smartwatch telling you you’ve been sitting too long or congratulating you on that intense running session. These devices, equipped with inertial sensors, can leverage the classification models that you have trained to offer these insights in real-time, enhancing user experience and promoting healthy behaviors.</li> </ol> <h3 id="summing-up"> <a href="#summing-up" class="anchor-heading" aria-labelledby="summing-up"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Summing Up </h3> <p>To wrap it up, while both step counting and activity classification revolve around understanding human movement, they cater to different scales of analysis. Step counting is about detecting individual events, while activity classification seeks to recognize broader patterns over longer timescales. As we transition from counting steps to recognizing activities, we move from a micro-scale, detection-based paradigm to a macro-scale, classification-based paradigm, better suited for understanding the intricate tapestry of human behavior.</p> <h2 id="implementing-feature-extraction-in-python"> <a href="#implementing-feature-extraction-in-python" class="anchor-heading" aria-labelledby="implementing-feature-extraction-in-python"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementing feature extraction in Python </h2> <p>Lets look at how you can split the data into windows of appropriate size and extract features from that window of data in python.</p> <h3 id="the-resample-function"> <a href="#the-resample-function" class="anchor-heading" aria-labelledby="the-resample-function"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The <code class="language-plaintext highlighter-rouge">resample</code> function </h3> <p>A python function that is particularly useful for converting raw data into a feature vector is the resample function. Lets take the case of accelerometer data with three orthogonal axes: X, Y, and Z.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Assuming your data frame 'df' has a DateTime index and columns 'x', 'y', and 'z' for accelerometer readings.
</span><span class="n">resampled_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">resample</span><span class="p">(</span><span class="s">'100L'</span><span class="p">):</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">frame</span><span class="p">[</span><span class="s">'time'</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span>
    <span class="n">frame</span><span class="p">[</span><span class="s">'x_mean'</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="s">'x'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">frame</span><span class="p">[</span><span class="s">'y_mean'</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">frame</span><span class="p">[</span><span class="s">'z_mean'</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="s">'z'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
    
    <span class="n">frame</span><span class="p">[</span><span class="s">'x_std'</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="s">'x'</span><span class="p">].</span><span class="n">std</span><span class="p">()</span>
    <span class="n">frame</span><span class="p">[</span><span class="s">'y_std'</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">std</span><span class="p">()</span>
    <span class="n">frame</span><span class="p">[</span><span class="s">'z_std'</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="s">'z'</span><span class="p">].</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">resampled_data</span> <span class="o">=</span> <span class="n">resampled_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <p>In this code:</p> <ul> <li>We resample the raw accelerometer data at 100 milliseconds intervals (‘100L’).</li> <li>For each window, we compute the mean and standard deviation for the X, Y, and Z accelerometer readings.</li> <li>We create a dictionary (frame) for each window, populate it with the computed features and the time stamp (t), and then append it to a new DataFrame (resampled_data).</li> </ul> <p>After executing this code, resampled_data will hold the resampled accelerometer data with features calculated for each window. Using a dictionary like this streamlines the process of iterative feature engineering and DataFrame population. The <code class="language-plaintext highlighter-rouge">append</code> method of pandas DataFrame can easily ingest dictionaries, where each key becomes a column in the DataFrame, and the corresponding value becomes the row entry for that column.</p> <h2 id="notebook-step-counting-with-find-peaks-html-ipynb"> <a href="#notebook-step-counting-with-find-peaks-html-ipynb" class="anchor-heading" aria-labelledby="notebook-step-counting-with-find-peaks-html-ipynb"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Notebook: Step Counting with Find Peaks [<a href="/mhealth-course/chapter3-activityrecognition/notebooks/Chapter3-Resampling.html">html</a>] [<a href="/mhealth-course/chapter3-activityrecognition/notebooks/Chapter3-Resampling.ipynb">ipynb</a>] </h2> <p>This notebook shows a step counter using <code class="language-plaintext highlighter-rouge">resample</code> and applies it to a synthetic temperature data trace. The initial temperature signal is generated at 10Hz over 2 weeks. The notebook shows how this can be resampled into hourly and daily intervals and a few features extracted for each window.</p> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
